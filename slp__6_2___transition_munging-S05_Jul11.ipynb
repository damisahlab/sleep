{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime\n",
    "\n",
    "import mne\n",
    "from mne.time_frequency import tfr_array_morlet\n",
    "\n",
    "import utils__config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Z:\\\\Layton\\\\Sleep_083023'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(utils__config.working_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S05, Jul 11:\n",
    "# 11700 (into)\n",
    "# 15600 (N3 -> N2)\n",
    "# 16500 (out)\n",
    "# 18600 (into)\n",
    "# 21360 (out)\n",
    "\n",
    "# S05, Jul 12:\n",
    "# 9900 (into)\n",
    "# 13950 (out)\n",
    "# 17700 (into)\n",
    "\n",
    "# S05, Jul 13:\n",
    "# 7380 (into)\n",
    "# 10800 (out)\n",
    "# 12300 (into)\n",
    "# 16200 (out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'Cache/Subject05/Jul11/S05_'\n",
    "fif_path = f'{base_path}Jul11_256hz.fif'\n",
    "legui_path = 'Cache/Subject05/S05_electrodes.csv'\n",
    "\n",
    "tpoint = 11700 # transition point between awake/sleep\n",
    "window = 600 # time before & after the transition point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_path = f'{base_path}SW.csv'\n",
    "spike_path = f'{base_path}spikes.csv'\n",
    "bad_channel_path = f'{base_path}bad_channels.csv'\n",
    "best_channel_path = f'{base_path}best_channels.csv'\n",
    "\n",
    "suffix = f't{tpoint}.csv'\n",
    "\n",
    "spectro_out = f'{base_path}spectro_{suffix}'\n",
    "raw_out = f'{base_path}raw_{suffix}'\n",
    "swa_out = f'{base_path}swa_{suffix}'\n",
    "beta_out = f'{base_path}beta_{suffix}'\n",
    "sw_out = f'{base_path}sw_{suffix}'\n",
    "spike_out = f'{base_path}spike_{suffix}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_freq = 256 # sampling frequency of the raw FIF file\n",
    "tfr_decimation = 1 # decimation by Morlet when calculating TFR\n",
    "mean_bin_division = 128 # division factor to bin samples into mean\n",
    "rolling_mean_samples = 30 # number of samples over which to calculate rolling mean\n",
    "#sd_gaussian_window = 10 # larger the number, the more equal weighting in the window\n",
    "spectrogram_channels = ['C4', 'LOF9'] # these will be your choices for spectrogram "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file Cache/Subject05/Jul11/S05_Jul11_256hz.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lal85\\AppData\\Local\\Temp\\2\\ipykernel_9040\\69444552.py:1: RuntimeWarning: This filename (Cache/Subject05/Jul11/S05_Jul11_256hz.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  spectro = mne.io.read_raw_fif(fif_path, preload = True, verbose = None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 7249663 =      0.000 ... 28318.996 secs\n",
      "Ready.\n",
      "Opening raw data file Z:\\Layton\\Sleep_083023\\Cache\\Subject05\\Jul11\\S05_Jul11_256hz-1.fif...\n",
      "    Range : 7249664 ... 8921599 =  28319.000 ... 34849.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 8921599  =      0.000 ... 34849.996 secs...\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    }
   ],
   "source": [
    "spectro = mne.io.read_raw_fif(fif_path, preload = True, verbose = None)\n",
    "spectro.pick_channels(ch_names = spectrogram_channels)\n",
    "spectro_chan_ordered = spectro.ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   22.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Get Morlet TFR\n",
    "ts_array = spectro.get_data(units = dict(eeg = 'uV'))\n",
    "ts_array = ts_array[np.newaxis, :, :]\n",
    "\n",
    "# Get timestamps for each sample\n",
    "timestamps = spectro.times\n",
    "\n",
    "# Create time-frequency representation\n",
    "# using the Morlet Wavelet transform:\n",
    "freqs = np.arange(1, 26, 1)\n",
    "\n",
    "tfr = tfr_array_morlet(ts_array, \n",
    "                       sfreq = spectro.info['sfreq'],\n",
    "                       freqs = freqs, \n",
    "                       n_cycles = 6.0,\n",
    "                       zero_mean = False, \n",
    "                       use_fft = True, \n",
    "                       output = 'power', \n",
    "                       decim = tfr_decimation,\n",
    "                       n_jobs = 4, \n",
    "                       verbose = None)\n",
    "\n",
    "# Remove the dummy dimension (that was required\n",
    "# due to formatting expectations of MNE Morlet):\n",
    "tfr = np.squeeze(tfr)\n",
    "\n",
    "# Convert to Xarray as an intermediate step in\n",
    "# getting data into Pandas long (2d) format:\n",
    "tfr = xr.DataArray(tfr,\n",
    "                   dims = ('channel', 'frequency', 'seconds'),\n",
    "                   coords = {'channel' : spectro_chan_ordered,\n",
    "                             'frequency' : freqs,\n",
    "                             'seconds' : timestamps})\n",
    "\n",
    "tfr = tfr.to_dataframe(name = 'power').reset_index()\n",
    "\n",
    "# Frequency-wise log10 normalization\n",
    "tfr['meanpower'] = tfr.groupby(['channel', 'frequency'])['power'].transform('mean')\n",
    "tfr['log_meanpower'] = 10 * np.log10(tfr['meanpower'])\n",
    "\n",
    "tfr['logpower'] = 10 * np.log10(tfr['power'])\n",
    "tfr['logpower_mean'] = tfr.groupby(['channel', 'frequency'])['logpower'].transform('mean')\n",
    "\n",
    "tfr['logmpower_freq'] = tfr['logpower'] - tfr['log_meanpower']\n",
    "tfr['logpower_freq'] = tfr['logpower'] - tfr['logpower_mean']\n",
    "\n",
    "tfr.drop(columns = ['meanpower', 'log_meanpower', 'logpower_mean'], inplace = True)\n",
    "\n",
    "# Group by frequency and time bin; define the time bin using floor\n",
    "# division of seconds by your desired decimation factor (optional step)\n",
    "tfr['time_bin'] = tfr.groupby(['channel', 'frequency']).cumcount() + 1\n",
    "tfr['time_bin'] = tfr['time_bin'] // mean_bin_division\n",
    "tfr = tfr.groupby(['channel', 'frequency', 'time_bin']).mean()\n",
    "tfr = tfr.reset_index()\n",
    "\n",
    "# Rolling mean to smooth TFR (optional step)\n",
    "true_seconds = tfr['seconds']\n",
    "\n",
    "# tfr = tfr.groupby(['channel', 'frequency']).rolling(window = rolling_mean_samples, \n",
    "#                                                     min_periods = 1, \n",
    "#                                                     center = True, \n",
    "#                                                     win_type = 'gaussian').mean(std = sd_gaussian_window)\n",
    "\n",
    "tfr = tfr.groupby(['channel', 'frequency']).rolling(window = rolling_mean_samples, \n",
    "                                                    min_periods = 1, \n",
    "                                                    center = True, \n",
    "                                                    win_type = 'gaussian').mean()\n",
    "\n",
    "tfr = tfr.reset_index()\n",
    "tfr.drop(columns = ['level_2'], inplace = True)\n",
    "\n",
    "tfr['seconds'] = true_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectro = tfr.loc[(tfr.seconds >= tpoint - window) & (tfr.seconds <= tpoint + window)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Traces (Raw + Beta + SWA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file Cache/Subject05/Jul11/S05_Jul11_256hz.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lal85\\AppData\\Local\\Temp\\2\\ipykernel_9040\\1609598292.py:1: RuntimeWarning: This filename (Cache/Subject05/Jul11/S05_Jul11_256hz.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(fif_path, preload = True, verbose = None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 7249663 =      0.000 ... 28318.996 secs\n",
      "Ready.\n",
      "Opening raw data file Z:\\Layton\\Sleep_083023\\Cache\\Subject05\\Jul11\\S05_Jul11_256hz-1.fif...\n",
      "    Range : 7249664 ... 8921599 =  28319.000 ... 34849.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 8921599  =      0.000 ... 34849.996 secs...\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lal85\\AppData\\Local\\Temp\\2\\ipykernel_9040\\1609598292.py:13: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  raw.pick_channels(ch_names = best_channels['Channel'].tolist())\n"
     ]
    }
   ],
   "source": [
    "raw = mne.io.read_raw_fif(fif_path, preload = True, verbose = None)\n",
    "\n",
    "# Select only macroelectrodes\n",
    "raw.pick_types(seeg = True, ecog = True)\n",
    "\n",
    "# Remove rejected channels\n",
    "bad_channels = pd.read_csv(bad_channel_path)\n",
    "bad_channels = bad_channels[bad_channels['channel'].isin(raw.ch_names)]\n",
    "raw.drop_channels(ch_names = bad_channels['channel'].astype('string'))\n",
    "\n",
    "# Select channels with the most SW's in each ROI\n",
    "best_channels = pd.read_csv(best_channel_path)\n",
    "raw.pick_channels(ch_names = best_channels['Channel'].tolist())\n",
    "\n",
    "# Save channel names for later use\n",
    "ch_names = raw.ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 4 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 4.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 5.00 Hz)\n",
      "- Filter length: 423 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  12 | elapsed:    3.1s remaining:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  12 | elapsed:    3.2s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  12 | elapsed:    3.4s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    3.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 15 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 15.00\n",
      "- Lower transition bandwidth: 3.75 Hz (-6 dB cutoff frequency: 13.12 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 227 samples (0.887 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  12 | elapsed:    1.2s remaining:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  12 | elapsed:    1.4s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  12 | elapsed:    1.6s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>July 11, 2023  23:35:16 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>0 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>12 sEEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>256.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>15.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>30.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>S05_Jul11_256hz.fif&lt;br&gt;S05_Jul11_256hz-1.fif</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>09:40:50 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Raw | S05_Jul11_256hz.fif, 12 x 8921600 (34850.0 s), ~816.8 MB, data loaded>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get low-passed SWA trace\n",
    "swa = raw.copy()\n",
    "swa.filter(l_freq = None, h_freq = 4, n_jobs = -1)\n",
    "\n",
    "# Get high-passed Beta trace\n",
    "beta = raw.copy()\n",
    "beta.filter(l_freq = 15, h_freq = 30, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SWA Trace data\n",
    "swa = swa.crop(tmin = tpoint - window, tmax = tpoint + window)\n",
    "swa_seconds = swa.times\n",
    "\n",
    "swa = swa.get_data()\n",
    "swa = xr.DataArray(swa,\n",
    "                   dims = ('channel', 'seconds'),\n",
    "                   coords = {'channel' : ch_names,\n",
    "                             'seconds' : swa_seconds})\n",
    "swa = swa.to_dataframe(name = 'amplitude').reset_index()\n",
    "\n",
    "swa['seconds'] = swa['seconds'] + (tpoint - window) # re-reference to total recording\n",
    "\n",
    "# Beta Trace data\n",
    "beta = beta.crop(tmin = tpoint - window, tmax = tpoint + window)\n",
    "beta_seconds = beta.times\n",
    "\n",
    "beta = beta.get_data()\n",
    "beta = xr.DataArray(beta,\n",
    "                    dims = ('channel', 'seconds'),\n",
    "                    coords = {'channel' : ch_names,\n",
    "                              'seconds' : beta_seconds})\n",
    "beta = beta.to_dataframe(name = 'amplitude').reset_index()\n",
    "\n",
    "beta['seconds'] = beta['seconds'] + (tpoint - window)\n",
    "\n",
    "# Raw Trace data\n",
    "raw = raw.crop(tmin = tpoint - window, tmax = tpoint + window)\n",
    "raw_seconds = raw.times\n",
    "\n",
    "raw = raw.get_data()\n",
    "raw = xr.DataArray(raw,\n",
    "                     dims = ('channel', 'seconds'),\n",
    "                     coords = {'channel' : ch_names,\n",
    "                               'seconds' : raw_seconds})\n",
    "raw = raw.to_dataframe(name = 'amplitude').reset_index()\n",
    "\n",
    "raw['seconds'] = raw['seconds'] + (tpoint - window)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slow Waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Slow Wave data\n",
    "sw_times = pd.read_csv(sw_path)\n",
    "\n",
    "# Merge with LeGUI to get channel laterality\n",
    "legui = pd.read_csv(legui_path)\n",
    "legui = legui[['elec_label', 'hemisphere', 'roi_1']]\n",
    "legui.columns = ['Channel', 'laterality', 'region']\n",
    "sw_times = sw_times.merge(legui, on = 'Channel', how = 'inner')\n",
    "\n",
    "# Select and rename SW columns\n",
    "sw_times = sw_times[['ID', 'Channel', 'laterality', 'region', 'Start', 'End',\n",
    "                     'NegPeak', 'MidCrossing', 'PosPeak']]\n",
    "sw_times.columns = ['sw_id', 'channel_id', 'sw_laterality', 'sw_region', 'start', 'end',\n",
    "                    'negative_peak', 'mid_crossing', 'positive_peak']\n",
    "\n",
    "# Only keep SW's from channels contained in the final Raw selection\n",
    "sw_times = sw_times[sw_times['channel_id'].isin(ch_names)]\n",
    "\n",
    "# Cropping\n",
    "sw_times = sw_times.loc[(sw_times.start >= tpoint - window) & (sw_times.end <= tpoint + window)]\n",
    "sw_times = sw_times[['channel_id', 'start', 'end']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spike data\n",
    "spikes = pd.read_csv(spike_path)\n",
    "spikes = spikes[['unit_id', 'seconds', 'unit_laterality', 'unit_region']]\n",
    "\n",
    "# Select only spikes in the time window\n",
    "spikes = spikes.loc[(spikes.seconds >= tpoint - window) & (spikes.seconds <= tpoint + window)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectro.to_csv(spectro_out, index = False)\n",
    "swa.to_csv(swa_out, index = False)\n",
    "beta.to_csv(beta_out, index = False)\n",
    "raw.to_csv(raw_out, index = False)\n",
    "sw_times.to_csv(sw_out, index = False)\n",
    "spikes.to_csv(spike_out, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bceaa3bdda3825794b37c15d2000316b6f4a45a3d4f5e14660beed4f1d5f7638"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
