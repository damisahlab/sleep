{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime\n",
    "\n",
    "import mne\n",
    "from mne.time_frequency import tfr_array_morlet\n",
    "\n",
    "import utils__config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\My Drive\\\\Residency\\\\Research\\\\Lab - Damisah\\\\Project - Sleep'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(utils__config.working_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fif_path = 'Cache/Subject01/S01_Feb02_256hz.fif'\n",
    "sw_path = 'Cache/Subject01/S01_SW.csv'\n",
    "spike_path = 'Cache/Subject01/S01_spikes.csv'\n",
    "legui_path = 'Cache/Subject01/S01_electrodes.csv'\n",
    "bad_channel_path = 'Cache/Subject01/S01_bad_channels.csv'\n",
    "best_channel_path = 'Cache/Subject01/S01_best_channels.csv'\n",
    "\n",
    "# fif_path = 'Cache/Subject02/S02_Apr27_256hz.fif'\n",
    "# sw_path = 'Cache/Subject02/S02_SW.csv'\n",
    "# spike_path = 'Cache/Subject02/S02_spikes.csv'\n",
    "# legui_path = 'Cache/Subject02/S02_electrodes.csv'\n",
    "# bad_channel_path = 'Cache/Subject02/S02_bad_channels.csv'\n",
    "# best_channel_path = 'Cache/Subject02/S02_best_channels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectro_out = 'Cache/Subject01/S01_spectro_t5760.csv'\n",
    "raw_out = 'Cache/Subject01/S01_raw_t5760.csv'\n",
    "swa_out = 'Cache/Subject01/S01_swa_t5760.csv'\n",
    "beta_out = 'Cache/Subject01/S01_beta_t5760.csv'\n",
    "sw_out = 'Cache/Subject01/S01_sw_t5760.csv'\n",
    "spike_out = 'Cache/Subject01/S01_spike_t5760.csv'\n",
    "\n",
    "#S01-1: 1920 +/- 340 (zoom 1700, 2140 +/- 15)\n",
    "#S01-2: 3680 +/- 480 (zoom +/- 60)\n",
    "#S01-3: 4140 +/- 480 (zoom 3840, 4440 +/- 15)\n",
    "#S01-4: 5715 +/- 180 (zoom +/- 30)\n",
    "\n",
    "#S01-Experiment: 5760 +/- 340 (zoom 5540, 5980 +/- 15)\n",
    "\n",
    "tpoint = 5760 # transition point between awake/sleep\n",
    "window = 340 # time before & after the transition point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_freq = 256 # sampling frequency of the raw FIF file\n",
    "tfr_decimation = 1 # decimation by Morlet when calculating TFR\n",
    "mean_bin_division = 128 # division factor to bin samples into mean\n",
    "rolling_mean_samples = 30 # number of samples over which to calculate rolling mean\n",
    "#sd_gaussian_window = 10 # larger the number, the more equal weighting in the window\n",
    "spectrogram_channels = ['C4', 'LOF1', 'LOF9', 'ROF1', 'RPI11'] # these will be your choices for spectrogram "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file Cache/Subject01/S01_Feb02_256hz.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Layton\\AppData\\Local\\Temp\\ipykernel_22332\\69444552.py:1: RuntimeWarning: This filename (Cache/Subject01/S01_Feb02_256hz.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  spectro = mne.io.read_raw_fif(fif_path, preload = True, verbose = None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isotrak not found\n",
      "    Range : 0 ... 1843573 =      0.000 ...  7201.457 secs\n",
      "Ready.\n",
      "Reading 0 ... 1843573  =      0.000 ...  7201.457 secs...\n"
     ]
    }
   ],
   "source": [
    "spectro = mne.io.read_raw_fif(fif_path, preload = True, verbose = None)\n",
    "spectro.pick_channels(ch_names = spectrogram_channels)\n",
    "spectro_chan_ordered = spectro.ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   16.5s finished\n",
      "C:\\Users\\Layton\\AppData\\Local\\Temp\\ipykernel_22332\\521218072.py:59: FutureWarning: Passing additional kwargs to RollingGroupby.mean has no impact on the result and is deprecated. This will raise a TypeError in a future version of pandas.\n",
      "  tfr = tfr.groupby(['channel', 'frequency']).rolling(window = rolling_mean_samples,\n"
     ]
    }
   ],
   "source": [
    "# Get Morlet TFR\n",
    "ts_array = spectro.get_data(units = dict(eeg = 'uV'))\n",
    "ts_array = ts_array[np.newaxis, :, :]\n",
    "\n",
    "# Get timestamps for each sample\n",
    "timestamps = spectro.times\n",
    "\n",
    "# Create time-frequency representation\n",
    "# using the Morlet Wavelet transform:\n",
    "freqs = np.arange(1, 26, 1)\n",
    "\n",
    "tfr = tfr_array_morlet(ts_array, \n",
    "                       sfreq = spectro.info['sfreq'],\n",
    "                       freqs = freqs, \n",
    "                       n_cycles = 6.0,\n",
    "                       zero_mean = False, \n",
    "                       use_fft = True, \n",
    "                       output = 'power', \n",
    "                       decim = tfr_decimation,\n",
    "                       n_jobs = 4, \n",
    "                       verbose = None)\n",
    "\n",
    "# Remove the dummy dimension (that was required\n",
    "# due to formatting expectations of MNE Morlet):\n",
    "tfr = np.squeeze(tfr)\n",
    "\n",
    "# Convert to Xarray as an intermediate step in\n",
    "# getting data into Pandas long (2d) format:\n",
    "tfr = xr.DataArray(tfr,\n",
    "                   dims = ('channel', 'frequency', 'seconds'),\n",
    "                   coords = {'channel' : spectro_chan_ordered,\n",
    "                             'frequency' : freqs,\n",
    "                             'seconds' : timestamps})\n",
    "\n",
    "tfr = tfr.to_dataframe(name = 'power').reset_index()\n",
    "\n",
    "# Frequency-wise log10 normalization\n",
    "tfr['meanpower'] = tfr.groupby(['channel', 'frequency'])['power'].transform('mean')\n",
    "tfr['log_meanpower'] = 10 * np.log10(tfr['meanpower'])\n",
    "\n",
    "tfr['logpower'] = 10 * np.log10(tfr['power'])\n",
    "tfr['logpower_mean'] = tfr.groupby(['channel', 'frequency'])['logpower'].transform('mean')\n",
    "\n",
    "tfr['logmpower_freq'] = tfr['logpower'] - tfr['log_meanpower']\n",
    "tfr['logpower_freq'] = tfr['logpower'] - tfr['logpower_mean']\n",
    "\n",
    "tfr.drop(columns = ['meanpower', 'log_meanpower', 'logpower_mean'], inplace = True)\n",
    "\n",
    "# Group by frequency and time bin; define the time bin using floor\n",
    "# division of seconds by your desired decimation factor (optional step)\n",
    "tfr['time_bin'] = tfr.groupby(['channel', 'frequency']).cumcount() + 1\n",
    "tfr['time_bin'] = tfr['time_bin'] // mean_bin_division\n",
    "tfr = tfr.groupby(['channel', 'frequency', 'time_bin']).mean()\n",
    "tfr = tfr.reset_index()\n",
    "\n",
    "# Rolling mean to smooth TFR (optional step)\n",
    "true_seconds = tfr['seconds']\n",
    "\n",
    "# tfr = tfr.groupby(['channel', 'frequency']).rolling(window = rolling_mean_samples, \n",
    "#                                                     min_periods = 1, \n",
    "#                                                     center = True, \n",
    "#                                                     win_type = 'gaussian').mean(std = sd_gaussian_window)\n",
    "\n",
    "tfr = tfr.groupby(['channel', 'frequency']).rolling(window = rolling_mean_samples, \n",
    "                                                    min_periods = 1, \n",
    "                                                    center = True, \n",
    "                                                    win_type = 'gaussian').mean()\n",
    "\n",
    "tfr = tfr.reset_index()\n",
    "tfr.drop(columns = ['level_2'], inplace = True)\n",
    "\n",
    "tfr['seconds'] = true_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectro = tfr.loc[(tfr.seconds >= tpoint - window) & (tfr.seconds <= tpoint + window)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Traces (Raw + Beta + SWA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file Cache/Subject01/S01_Feb02_256hz.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Layton\\AppData\\Local\\Temp\\ipykernel_22332\\1609598292.py:1: RuntimeWarning: This filename (Cache/Subject01/S01_Feb02_256hz.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(fif_path, preload = True, verbose = None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isotrak not found\n",
      "    Range : 0 ... 1843573 =      0.000 ...  7201.457 secs\n",
      "Ready.\n",
      "Reading 0 ... 1843573  =      0.000 ...  7201.457 secs...\n"
     ]
    }
   ],
   "source": [
    "raw = mne.io.read_raw_fif(fif_path, preload = True, verbose = None)\n",
    "\n",
    "# Select only macroelectrodes\n",
    "raw.pick_types(seeg = True, ecog = True)\n",
    "\n",
    "# Remove rejected channels\n",
    "bad_channels = pd.read_csv(bad_channel_path)\n",
    "bad_channels = bad_channels[bad_channels['channel'].isin(raw.ch_names)]\n",
    "raw.drop_channels(ch_names = bad_channels['channel'].astype('string'))\n",
    "\n",
    "# Select channels with the most SW's in each ROI\n",
    "best_channels = pd.read_csv(best_channel_path)\n",
    "raw.pick_channels(ch_names = best_channels['Channel'].tolist())\n",
    "\n",
    "# Save channel names for later use\n",
    "ch_names = raw.ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 4 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 4.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 5.00 Hz)\n",
      "- Filter length: 423 samples (1.652 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:    4.2s remaining:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    4.2s remaining:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:    4.3s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 15 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 15.00\n",
      "- Lower transition bandwidth: 3.75 Hz (-6 dB cutoff frequency: 13.12 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 227 samples (0.887 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:    0.1s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>February 02, 2022  05:41:39 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>Not available</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>15 sEEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>256.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>15.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>30.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>S01_Feb02_256hz.fif</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>02:00:02 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Raw | S01_Feb02_256hz.fif, 15 x 1843574 (7201.5 s), ~211.0 MB, data loaded>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get low-passed SWA trace\n",
    "swa = raw.copy()\n",
    "swa.filter(l_freq = None, h_freq = 4, n_jobs = -1)\n",
    "\n",
    "# Get high-passed Beta trace\n",
    "beta = raw.copy()\n",
    "beta.filter(l_freq = 15, h_freq = 30, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SWA Trace data\n",
    "swa = swa.crop(tmin = tpoint - window, tmax = tpoint + window)\n",
    "swa_seconds = swa.times\n",
    "\n",
    "swa = swa.get_data()\n",
    "swa = xr.DataArray(swa,\n",
    "                   dims = ('channel', 'seconds'),\n",
    "                   coords = {'channel' : ch_names,\n",
    "                             'seconds' : swa_seconds})\n",
    "swa = swa.to_dataframe(name = 'amplitude').reset_index()\n",
    "\n",
    "swa['seconds'] = swa['seconds'] + (tpoint - window) # re-reference to total recording\n",
    "\n",
    "# Beta Trace data\n",
    "beta = beta.crop(tmin = tpoint - window, tmax = tpoint + window)\n",
    "beta_seconds = beta.times\n",
    "\n",
    "beta = beta.get_data()\n",
    "beta = xr.DataArray(beta,\n",
    "                    dims = ('channel', 'seconds'),\n",
    "                    coords = {'channel' : ch_names,\n",
    "                              'seconds' : beta_seconds})\n",
    "beta = beta.to_dataframe(name = 'amplitude').reset_index()\n",
    "\n",
    "beta['seconds'] = beta['seconds'] + (tpoint - window)\n",
    "\n",
    "# Raw Trace data\n",
    "raw = raw.crop(tmin = tpoint - window, tmax = tpoint + window)\n",
    "raw_seconds = raw.times\n",
    "\n",
    "raw = raw.get_data()\n",
    "raw = xr.DataArray(raw,\n",
    "                     dims = ('channel', 'seconds'),\n",
    "                     coords = {'channel' : ch_names,\n",
    "                               'seconds' : raw_seconds})\n",
    "raw = raw.to_dataframe(name = 'amplitude').reset_index()\n",
    "\n",
    "raw['seconds'] = raw['seconds'] + (tpoint - window)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slow Waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Slow Wave data\n",
    "sw_times = pd.read_csv(sw_path)\n",
    "\n",
    "# Merge with LeGUI to get channel laterality\n",
    "legui = pd.read_csv(legui_path)\n",
    "legui = legui[['elec_label', 'hemisphere', 'roi_1']]\n",
    "legui.columns = ['Channel', 'laterality', 'region']\n",
    "sw_times = sw_times.merge(legui, on = 'Channel', how = 'inner')\n",
    "\n",
    "# Select and rename SW columns\n",
    "sw_times = sw_times[['ID', 'Channel', 'laterality', 'region', 'Start', 'End',\n",
    "                     'NegPeak', 'MidCrossing', 'PosPeak']]\n",
    "sw_times.columns = ['sw_id', 'channel_id', 'sw_laterality', 'sw_region', 'start', 'end',\n",
    "                    'negative_peak', 'mid_crossing', 'positive_peak']\n",
    "\n",
    "# Only keep SW's from channels contained in the final Raw selection\n",
    "sw_times = sw_times[sw_times['channel_id'].isin(ch_names)]\n",
    "\n",
    "# Cropping\n",
    "sw_times = sw_times.loc[(sw_times.start >= tpoint - window) & (sw_times.end <= tpoint + window)]\n",
    "sw_times = sw_times[['channel_id', 'start', 'end']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spike data\n",
    "spikes = pd.read_csv(spike_path)\n",
    "spikes = spikes[['unit_id', 'seconds', 'unit_laterality', 'unit_region']]\n",
    "\n",
    "# Select only spikes in the time window\n",
    "spikes = spikes.loc[(spikes.seconds >= tpoint - window) & (spikes.seconds <= tpoint + window)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectro.to_csv(spectro_out, index = False)\n",
    "swa.to_csv(swa_out, index = False)\n",
    "beta.to_csv(beta_out, index = False)\n",
    "raw.to_csv(raw_out, index = False)\n",
    "sw_times.to_csv(sw_out, index = False)\n",
    "spikes.to_csv(spike_out, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bceaa3bdda3825794b37c15d2000316b6f4a45a3d4f5e14660beed4f1d5f7638"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
