{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils__config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Z:\\\\Layton\\\\Sleep_083023'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(utils__config.working_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fif_path = 'Cache/Subject05/Jul11/S05_Jul11_256hz.fif'\n",
    "dict_path = 'Data/Subject05/Jul11/S05_dictionary.xlsx'\n",
    "\n",
    "sw_path = 'Cache/Subject05/Jul11/S05_SW.csv'\n",
    "kc_path = 'Cache/Subject05/Jul11/S05_KC.csv'\n",
    "save_path = 'Cache/Subject05/Jul11/S05_event_epochs.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_freq = 256"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file Cache/Subject05/Jul11/S05_Jul11_256hz.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lal85\\AppData\\Local\\Temp\\2\\ipykernel_42844\\2216903412.py:2: RuntimeWarning: This filename (Cache/Subject05/Jul11/S05_Jul11_256hz.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(fif_path, preload = True, verbose = None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 7249663 =      0.000 ... 28318.996 secs\n",
      "Ready.\n",
      "Opening raw data file Z:\\Layton\\Sleep_083023\\Cache\\Subject05\\Jul11\\S05_Jul11_256hz-1.fif...\n",
      "    Range : 7249664 ... 8921599 =  28319.000 ... 34849.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 8921599  =      0.000 ... 34849.996 secs...\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=8921600\n",
      "    Range : 0 ... 8921599 =      0.000 ... 34849.996 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "# Load LFP data\n",
    "raw = mne.io.read_raw_fif(fif_path, preload = True, verbose = None)\n",
    "\n",
    "# Record the first sample (which is not 0 since the Raw\n",
    "# file was cropped from the original); you will need this\n",
    "# to appropriately select the sleep event sample number\n",
    "first_raw_sample = raw.first_samp\n",
    "\n",
    "# Remove unnecessary channels\n",
    "#dictionary = pd.read_excel(dict_path)\n",
    "#dictionary = dictionary[(dictionary['type'] == 'macro') & (dictionary['status'] == 'accept')]['name'].tolist()\n",
    "#raw.pick_channels(ch_names = dictionary)\n",
    "\n",
    "# Create a dummy numpy event array and MNE info object\n",
    "# and use them to create an empty dummy Raw channel\n",
    "events_info = mne.create_info(ch_names = ['events'], \n",
    "                              sfreq = raw.info['sfreq'], \n",
    "                              ch_types = ['stim'])\n",
    "\n",
    "empty_events = np.zeros((1, len(raw.times)))\n",
    "\n",
    "events_channel = mne.io.RawArray(data = empty_events, \n",
    "                                 info = events_info,\n",
    "                                 first_samp = first_raw_sample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slow Waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load detected slow waves\n",
    "sw_times = pd.read_csv(sw_path)\n",
    "sw_times = sw_times[['Channel', 'Start', 'End', 'Duration', 'NegPeak', 'MidCrossing', 'PosPeak']]\n",
    "sw_times.columns = ['channel', 'start', 'end', 'duration', 'neg_peak', 'mid_cross', 'pos_peak']\n",
    "\n",
    "# Find MNE sample times for when SW's were present\n",
    "sw_times['sample'] = (sw_times.neg_peak * sampling_freq) + first_raw_sample\n",
    "sw_times['sample'] = sw_times['sample'].round(0).astype('int64')\n",
    "\n",
    "# Create a numpy array formatted according to MNE requirements\n",
    "# (please note that the dummy_0 column is just a spacer and has \n",
    "#  no meaning except internally to MNE, which expects 0's; \n",
    "#  however, the event_id column should contain the integer that\n",
    "#  corresponds to the relevant event in your event dictionary)\n",
    "sw_times['dummy_0'] = 0\n",
    "sw_times['event_id'] = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load detected slow waves\n",
    "kc_times = pd.read_csv(kc_path)\n",
    "kc_times = kc_times[['Channel', 'Start', 'End', 'Duration', 'NegPeak', 'MidCrossing', 'PosPeak']]\n",
    "kc_times.columns = ['channel', 'start', 'end', 'duration', 'neg_peak', 'mid_cross', 'pos_peak']\n",
    "\n",
    "# Find MNE sample times for when SW's were present\n",
    "kc_times['sample'] = (kc_times.neg_peak * sampling_freq) + first_raw_sample\n",
    "kc_times['sample'] = kc_times['sample'].round(0).astype('int64')\n",
    "\n",
    "# Create a numpy array formatted according to MNE requirements\n",
    "# (please note that the dummy_0 column is just a spacer and has \n",
    "#  no meaning except internally to MNE, which expects 0's; \n",
    "#  however, the event_id column should contain the integer that\n",
    "#  corresponds to the relevant event in your event dictionary)\n",
    "kc_times['dummy_0'] = 0\n",
    "kc_times['event_id'] = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark events and export by channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "2450 events found\n",
      "Event IDs: [1]\n",
      "Not setting metadata\n",
      "2450 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2450 events and 1025 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1/17 [00:02<00:35,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "1476 events found\n",
      "Event IDs: [1]\n",
      "Not setting metadata\n",
      "1476 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1476 events and 1025 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 2/17 [00:04<00:29,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "1233 events found\n",
      "Event IDs: [1]\n",
      "Not setting metadata\n",
      "1233 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1233 events and 1025 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3/17 [00:05<00:25,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "2423 events found\n",
      "Event IDs: [1 2]\n",
      "Not setting metadata\n",
      "2423 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2423 events and 1025 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 4/17 [00:07<00:25,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "1682 events found\n",
      "Event IDs: [1]\n",
      "Not setting metadata\n",
      "1682 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1682 events and 1025 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 5/17 [00:09<00:23,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "922 events found\n",
      "Event IDs: [1]\n",
      "Not setting metadata\n",
      "922 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 922 events and 1025 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 6/17 [00:11<00:19,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "874 events found\n",
      "Event IDs: [1]\n",
      "Not setting metadata\n",
      "874 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 874 events and 1025 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 7/17 [00:12<00:17,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "1499 events found\n",
      "Event IDs: [1]\n",
      "Not setting metadata\n",
      "1499 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1499 events and 1025 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 8/17 [00:14<00:15,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "2252 events found\n",
      "Event IDs: [1]\n",
      "Not setting metadata\n",
      "2252 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2252 events and 1025 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 9/17 [00:16<00:15,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "1395 events found\n",
      "Event IDs: [1]\n",
      "Not setting metadata\n",
      "1395 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1395 events and 1025 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 10/17 [00:18<00:12,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "828 events found\n",
      "Event IDs: [1]\n",
      "Not setting metadata\n",
      "828 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 828 events and 1025 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 11/17 [00:20<00:10,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "2543 events found\n",
      "Event IDs: [1]\n",
      "Not setting metadata\n",
      "2543 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2543 events and 1025 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 12/17 [00:22<00:09,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "1137 events found\n",
      "Event IDs: [1]\n",
      "Not setting metadata\n",
      "1137 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1137 events and 1025 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 13/17 [00:24<00:07,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "1112 events found\n",
      "Event IDs: [1]\n",
      "Not setting metadata\n",
      "1112 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1112 events and 1025 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 14/17 [00:25<00:05,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "2284 events found\n",
      "Event IDs: [1]\n",
      "Not setting metadata\n",
      "2284 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2284 events and 1025 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 15/17 [00:28<00:03,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "1158 events found\n",
      "Event IDs: [1]\n",
      "Not setting metadata\n",
      "1158 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1158 events and 1025 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 16/17 [00:29<00:01,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "1545 events found\n",
      "Event IDs: [1]\n",
      "Not setting metadata\n",
      "1545 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1545 events and 1025 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:31<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "event_frame = pd.DataFrame()\n",
    "\n",
    "# Loop through only those channels with detected SW or KC\n",
    "sw_kc_channels = pd.concat([sw_times['channel'], kc_times['channel']]).unique()\n",
    "\n",
    "for channel in tqdm(sw_kc_channels):\n",
    "\n",
    "    # Create a channel-specific Raw object\n",
    "    temp_raw = raw.copy().pick_channels(ch_names = [channel])\n",
    "\n",
    "    # Create channel-specific Event numpy arrays\n",
    "    chan_sw = np.array(sw_times[sw_times.channel == channel][['sample', 'dummy_0', 'event_id']])\n",
    "    chan_kc = np.array(kc_times[kc_times.channel == channel][['sample', 'dummy_0', 'event_id']])\n",
    "\n",
    "    # Add the empty dummy channel to the data\n",
    "    temp_raw.add_channels([events_channel], force_update_info = True)\n",
    "\n",
    "    # Now update the dummy events ('stim') channel with the \n",
    "    # event times and then convert them to MNE events\n",
    "    event_dictionary = {'slow_wave' : 1}\n",
    "    \n",
    "    temp_raw.add_events(chan_sw, 'events')\n",
    "\n",
    "    # If any K-Complexes were detected, overwrite above\n",
    "    if (len(chan_kc) > 0):\n",
    "\n",
    "        event_dictionary = {'slow_wave' : 1,\n",
    "                            'k_complex' : 2}\n",
    "        \n",
    "        temp_raw.add_events(chan_kc, 'events')\n",
    "\n",
    "    # Find events\n",
    "    events = mne.find_events(raw = temp_raw, \n",
    "                             shortest_event = 1, # include events of length 1 sample \n",
    "                             initial_event = True) # include events occuring at sample 0\n",
    "\n",
    "    # Create an MNE Epochs object using the modified MNE Raw object\n",
    "    epochs = mne.Epochs(temp_raw, \n",
    "                        preload = True, \n",
    "                        events = events, \n",
    "                        event_id = event_dictionary, \n",
    "                        baseline = None, \n",
    "                        verbose = True, \n",
    "                        tmin = -2, \n",
    "                        tmax = 2, \n",
    "                        decim = 1)\n",
    "\n",
    "    # Drop the event channel before exporting data\n",
    "    epochs = epochs.drop_channels(['events'])\n",
    "\n",
    "    # Format the Epochs object into a pandas dataframe\n",
    "    epochs = epochs.to_data_frame(scalings = dict(seeg = 1e6, eeg = 1e6))\n",
    "    epochs = epochs.set_index(['time', 'condition', 'epoch']).stack().reset_index()\n",
    "    epochs.columns = ['time', 'condition', 'epoch', 'channel', 'value']\n",
    "\n",
    "    # Average sleep events within channel (optional)\n",
    "    epochs.drop(columns = ['epoch'], inplace = True)\n",
    "    epochs = epochs.groupby(['time', 'condition', 'channel']).mean().reset_index()\n",
    "\n",
    "    # Get data and annotate event type (SW/KC)\n",
    "    event_frame = pd.concat([event_frame, epochs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_frame.to_csv(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bceaa3bdda3825794b37c15d2000316b6f4a45a3d4f5e14660beed4f1d5f7638"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
